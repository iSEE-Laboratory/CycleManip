"""
Piper Real Environment for Policy Deployment
æä¾›ä¸ Base_Task å…¼å®¹çš„æ¥å£ï¼Œç”¨äºçœŸæœºéƒ¨ç½²
"""
import time
import numpy as np
from typing import Dict, Optional, List
from pathlib import Path
import cv2
import open3d as o3d
from termcolor import cprint

from .piper import PiperRobot
from .camera import RealSenseCamera, get_device_ids
import pyrealsense2 as rs

from .revo2.revo2Controler import Revo2HandController

import torch
import sys
sys.path.append('/home/dex/haoran/gello_software/third_party/pointnet2')
import pointnet2_utils

"""
åŒæ‰‹Piper çœŸæœºç¯å¢ƒç±»
"""


class PiperRealEnv:
    """Piper çœŸæœºç¯å¢ƒç±»
    
    æä¾›ä¸ä»¿çœŸç¯å¢ƒ Base_Task ç›¸ä¼¼çš„æ¥å£ï¼Œä½¿å¾—æ‰€æœ‰ policy å¯ä»¥æ— ç¼è¿ç§»åˆ°çœŸæœº
    """
    
    def __init__(
        self,
        policy: str = "unknown_policy",
        robot_ip: str = "can_right",
        init_pos = [0, 0, 0, 0, 0, 0, 0],
        step_lim: int = 1000,
        img_size: tuple = (640, 480),
    ):
        """
        Args:
            camera_config: ç›¸æœºé…ç½®å­—å…¸ï¼ŒåŒ…å«å„ä¸ªç›¸æœºçš„ device_id
            robot_ip: æœºå™¨äºº CAN æ¥å£åç§°
            step_lim: æœ€å¤§æ‰§è¡Œæ­¥æ•°
            img_size: å›¾åƒå°ºå¯¸ (width, height)
        """
        cprint("=" * 50, "cyan")
        cprint(f"åˆå§‹åŒ– Piper {policy} çœŸæœºç¯å¢ƒ...", "cyan", attrs=["bold"])
        cprint("=" * 50, "cyan")

        self.policy = policy

        # åˆå§‹åŒ–æ‰‹
        self.hand_left = Revo2HandController(port='/dev/ttyUSB1', slave_id=0x7e)  # å·¦æ‰‹
        self.hand_right = Revo2HandController(port='/dev/ttyUSB0', slave_id=0x7f)  # å³æ‰‹
        
        # åˆå§‹åŒ–æœºå™¨äºº
        cprint(f"ğŸ¤– è¿æ¥æœºå™¨äºº: can_left å’Œ can_right", "yellow")
        self.robot_left = PiperRobot(robot_ip="can_left")
        self.robot_right = PiperRobot(robot_ip="can_right")

        self.init_pos = np.array(init_pos)
        
        print("åˆå§‹åŒ–ç›¸æœº...")
        # d455
        # self.camera = RealSenseCamera(device_id='215122251612', flip=False)
        # self.intrinsics = rs.intrinsics()
        # self.intrinsics.width, self.intrinsics.height = 640, 480
        # self.intrinsics.ppx, self.intrinsics.ppy = 323.6994934082031, 240.37545776367188
        # self.intrinsics.fx, self.intrinsics.fy = 382.5924072265625, 382.1819763183594
        # self.intrinsics.model = rs.distortion.brown_conrady
        # self.intrinsics.coeffs = [-0.05781254917383194, 0.07238195091485977, 0.00010194736387347803,
        #                     0.0006292760954238474, -0.023512376472353935]

        self.camera = RealSenseCamera(device_id='f1271156', flip=False)
        # L515-depth
        # self.intrinsics = rs.intrinsics()
        # self.intrinsics.width, self.intrinsics.height = 640, 480
        # self.intrinsics.ppx, self.intrinsics.ppy = 301.09375, 246.337890625
        # self.intrinsics.fx, self.intrinsics.fy = 459.8203125, 459.96484375
        # self.intrinsics.model = rs.distortion.none
        # self.intrinsics.coeffs = [0.0, 0.0, 0.0, 0.0, 0.0]

        # L515-rgb
        self.intrinsics = rs.intrinsics()
        self.intrinsics.width, self.intrinsics.height = 640, 480
        self.intrinsics.ppx, self.intrinsics.ppy = 330.53131103515625, 232.83041381835938
        self.intrinsics.fx, self.intrinsics.fy = 598.9841918945312, 599.3632202148438
        self.intrinsics.model = rs.distortion.brown_conrady
        self.intrinsics.coeffs = [0.16919225454330444, -0.5201395750045776, -0.0035975882783532143, -0.00044879087363369763, 0.4867783486843109]

        # GPUæ—‹è½¬
        theta_x = torch.deg2rad(torch.tensor(140., device='cuda'))
        theta_z = torch.deg2rad(torch.tensor(2.5, device='cuda'))
        R_x = torch.tensor([
            [1, 0, 0],
            [0, torch.cos(theta_x), -torch.sin(theta_x)],
            [0, torch.sin(theta_x), torch.cos(theta_x)]
        ], device='cuda')
        R_z = torch.tensor([
            [torch.cos(theta_z), -torch.sin(theta_z), 0],
            [torch.sin(theta_z), torch.cos(theta_z), 0],
            [0, 0, 1]
        ], device='cuda')
        R = R_z @ R_x
        self.R = R.T

        
        self.img_size = img_size

        self.instruction = None
        self.instruction_sim = None
        self.instruction_int = None
        
        # ç¯å¢ƒçŠ¶æ€
        self.step_lim = step_lim
        self.take_action_cnt = 0
        self.eval_success = False
        self.suc = 0
        self.test_num = 0

        self.first_time = True
        self.reset()
        
        cprint("âœ… Piper çœŸæœºç¯å¢ƒåˆå§‹åŒ–å®Œæˆ!", "green", attrs=["bold"])
        cprint("=" * 50, "cyan")
    
    def dofs(self) -> int:
        return 24
    
    def get_pcd(self, color_image, depth_image, intrinsics, device='cuda'):
        """GPUåŠ é€Ÿç‰ˆï¼Œä»RGB-Dç”Ÿæˆç‚¹äº‘"""
        # è½¬tensor
        color = torch.from_numpy(color_image.copy()).float().to(device)
        depth = torch.from_numpy(depth_image.copy()).float().to(device) * 0.001

        H, W = depth.shape
        v, u = torch.meshgrid(
            torch.arange(H, device=device),
            torch.arange(W, device=device),
            indexing='ij'
        )

        valid = depth > 1e-5
        z = depth[valid]
        x = (u[valid] - intrinsics.ppx) * z / intrinsics.fx
        y = (v[valid] - intrinsics.ppy) * z / intrinsics.fy

        points = torch.stack((x, y, z), dim=-1)
        colors = color[valid]

        points = points @ self.R

        valid = \
            (points[:, 0] < 2) & \
            (points[:, 1] > -3.65) & \
            (points[:, 2] > -5.75) & (points[:, 2] < -2)

        points, colors = points[valid], colors[valid]

        # print(f"ç‚¹äº‘åŸå§‹ç‚¹æ•°: {points.shape[0]}")

        if points.shape[0] > 2048:
            idx1 = torch.where(points[:, 1] > -3.6)[0]
            idx2 = torch.where((points[:, 1] <= -3.6) & (points[:, 1] > -3.65))[0]

            num1 = int(2048 * 0.75)
            num2 = 2048 - num1

            p1 = points[idx1].unsqueeze(0)
            p2 = points[idx2].unsqueeze(0)
            inds1 = pointnet2_utils.furthest_point_sample(p1, num1)
            inds2 = pointnet2_utils.furthest_point_sample(p2, num2)

            sampled_points = torch.cat([
                p1[0, inds1[0]], p2[0, inds2[0]]
            ], dim=0)
            sampled_colors = torch.cat([
                colors[idx1][inds1[0]], colors[idx2][inds2[0]]
            ], dim=0)

            idx = torch.randperm(2048, device=device)
            points = sampled_points[idx]
            colors = sampled_colors[idx]

        elif points.shape[0] < 2048:
            num_pad = 2048 - points.shape[0]
            pad_points = torch.zeros((num_pad, 3), device=device)
            pad_colors = torch.zeros((num_pad, 3), device=device)
            points = torch.cat([points, pad_points], dim=0)
            colors = torch.cat([colors, pad_colors], dim=0)
            idx = torch.randperm(2048, device=device)
            points = points[idx]
            colors = colors[idx]# ç”¨ä»¥è°ƒè¯•ï¼Œä¿å­˜è§‚æµ‹åˆ°æœ¬åœ°
            # import pickle as pkl
            # # ä¿å­˜åˆ°/home/dex/haoran/LoopBreaker/data/tmp
            # pkl.dump(obs, open(f"/home/dex/haoran/LoopBreaker/data/tmp/piper_real_dp3_obs_step{self.take_action_cnt}.pkl", "wb"))

            # input("[obs] æŸ¥çœ‹è§‚æµ‹ï¼ŒæŒ‰å›è½¦ç»§ç»­...")

            # print("state:", joint_positions)
            # print("ee_pos_quat:", ee_pos_quat)

            # input("[obs] æŸ¥çœ‹å®Œæ¯•ï¼ŒæŒ‰å›è½¦ç»§ç»­...")

        # åªåœ¨æœ€åè½¬æ¢ä¸ºnumpyè¿”å›
        return torch.cat([points, colors], dim=-1).cpu().numpy()

    
    def get_obs(self) -> Dict:
        """è·å–å½“å‰è§‚æµ‹
        
        Returns:
            {
                'joint_action': {
                    'vector': list[24],  # (6ä¸ªå…³èŠ‚è§’åº¦ + 6ä¸ªæ‰‹ä½ç½®) x 2 æ‰‹
                },
                'endpose': np.ndarray(14),  # (ä½ç½®+å››å…ƒæ•°) x 2 æ‰‹
                'pointcloud': np.ndarray(2048, 6)
            }
        """
        # æ ¹æ®policyæ„å»ºè§‚æµ‹å­—å…¸
        if self.policy == "DP3":
            # DP3 éœ€è¦ joint_action.vector å’Œ pointcloud
            # å¯¹äºylçš„æ¨¡å‹ï¼Œæˆ‘ä»¬è¿˜éœ€è¦ä¼ å…¥ instructionï¼Œinstruction_simï¼Œinstruction_int, ee_pos_quat
            # breakpoint()
            robot_obs_left = self.robot_left.get_observations()
            robot_obs_right = self.robot_right.get_observations()
            # åŸæ¥æ‹¿åˆ°çš„æ˜¯7ï¼Œè¿™é‡Œæ²¡æœ‰å¤¹çˆªï¼Œæ‰€ä»¥åªå–å‰6ä¸ª
            joint_positions_left = robot_obs_left["joint_positions"][:6]  # shape: (6,)
            ee_pos_quat_left = robot_obs_left["ee_pos_quat"]  # shape: (7,)
            joint_positions_right = robot_obs_right["joint_positions"][:6]  # shape: (6,)
            ee_pos_quat_right = robot_obs_right["ee_pos_quat"]  # shape: (7,)

            hand_state_left = np.array(self.hand_left.get_joint_positions(), dtype=np.float32) # (6,)
            # debug
            # hand_state_left = np.array([0, 1, 0, 0, 0, 0], dtype=np.float32)
            hand_state_right = np.array(self.hand_right.get_joint_positions(), dtype=np.float32) # (6,)
            # hand_state_right = np.array(self.init_pos[18:24], dtype=np.float32)

            joint_positions = np.concatenate([joint_positions_left, hand_state_left, joint_positions_right, hand_state_right])
            assert joint_positions.shape == (24,)
            ee_pos_quat = np.concatenate([ee_pos_quat_left, ee_pos_quat_right])
            assert ee_pos_quat.shape == (14,)

            # è·å–ç›¸æœºå›¾åƒ
            rgb, depth = self.camera.read(img_size=self.img_size)
            depth = depth.reshape(480, 640)
            pcd = self.get_pcd(rgb, depth, self.intrinsics)  # shape: (2048, 6)

            obs = {
                "joint_action": {
                    "vector": np.array(joint_positions),  # è¿”å› numpy arrayï¼Œä¸æ˜¯ listï¼
                },
                "endpose": np.array(ee_pos_quat).astype(np.float32),  # è¿”å› numpy arrayï¼Œä¸æ˜¯ listï¼

                "pointcloud": pcd,

                # instructions
                "instruction": self.instruction,
                "instruction_sim": self.instruction_sim,
                "instruction_int": self.instruction_int
            }

            # # ç”¨ä»¥è°ƒè¯•ï¼Œä¿å­˜è§‚æµ‹åˆ°æœ¬åœ°
            # import pickle as pkl
            # # ä¿å­˜åˆ°/home/dex/haoran/LoopBreaker/data/tmp
            # pkl.dump(obs, open(f"/home/dex/haoran/LoopBreaker/data/tmp/piper_real_dp3_obs_step{self.take_action_cnt}.pkl", "wb"))

            # input("[obs] æŸ¥çœ‹è§‚æµ‹ï¼ŒæŒ‰å›è½¦ç»§ç»­...")

            # print("state:", joint_positions)
            # print("ee_pos_quat:", ee_pos_quat)

            # input("[obs] æŸ¥çœ‹å®Œæ¯•ï¼ŒæŒ‰å›è½¦ç»§ç»­...")
            


        elif self.policy == "pi0":
            # pi0 éœ€è¦ joint_action.vector å’Œ head_camera.rgb
            robot_obs_left = self.robot_left.get_observations()
            robot_obs_right = self.robot_right.get_observations()
            joint_positions_left = robot_obs_left["joint_positions"]  # shape: (7,)
            joint_positions_right = robot_obs_right["joint_positions"]  # shape: (7,)

            joint_positions = np.concatenate([joint_positions_left, joint_positions_right])

            # è·å–ç›¸æœºå›¾åƒ
            rgb, _ = self.camera.read(img_size=self.img_size)
            
            obs = {
                "joint_action": {
                    "vector": np.array(joint_positions),  # è¿”å› numpy arrayï¼Œä¸æ˜¯ listï¼
                },
                "observation": {
                    "head_camera": {
                        "rgb": rgb,
                    },
                },  
            }

        else:
            raise ValueError(f"æœªæ”¯æŒçš„ policy ç±»å‹: {self.policy}")
            
        return obs
    
    def take_action(self, action: np.ndarray) -> None:
        """æ‰§è¡ŒåŠ¨ä½œ
        
        Args:
            action: åŠ¨ä½œæ•°ç»„ï¼Œshape: (24,)
                - å·¦è‡‚6ä¸ªå…³èŠ‚å¼§åº¦ + å·¦æ‰‹6ä¸ªå…³èŠ‚(0-1000æ•´æ•°) + å³è‡‚6ä¸ªå…³èŠ‚å¼§åº¦ + å³æ‰‹6ä¸ªå…³èŠ‚(0-1000æ•´æ•°)
        """
        self.take_action_cnt += 1
             
        # ç¡®ä¿æ˜¯ numpy æ•°ç»„
        action = np.array(action, dtype=np.float32)

        joint_left = action[:6]
        joint_left[5] += 0.4101523743

        joint_right = action[12:18]
        joint_right[5] += 0.4101523743

        left_arm_cmd = np.concatenate([joint_left, np.array([0])])
        left_hand_cmd = action[6:12]  # æ‰‹6ä¸ªå…³èŠ‚ (åŸå§‹å€¼ 0-1000)
        right_arm_cmd = np.concatenate([joint_right, np.array([0])])
        right_hand_cmd = action[18:24]  # æ‰‹6ä¸ªå…³èŠ‚ (åŸå§‹å€¼ 0-1000)

        # å‘é€æŒ‡ä»¤åˆ°æœºå™¨äºº
        self.robot_left.command_joint_state(left_arm_cmd, "state")
        self.robot_right.command_joint_state(right_arm_cmd, "state")
        self.hand_left.set_joint_positions(left_hand_cmd.astype(int).tolist())
        self.hand_right.set_joint_positions(right_hand_cmd.astype(int).tolist())
        
        cprint(f"â³ æ­¥æ•°: {self.take_action_cnt}/{self.step_lim}", "cyan", end="\r")
      
    def reset(self) -> None:
        """é‡ç½®æœºå™¨äººåˆ°åˆå§‹å§¿æ€"""
        # ç”¨ä¸€ä¸ªçº¿æ€§æ’å€¼å»æ§åˆ¶å¤¹çˆªåˆ°åˆå§‹ä½ç½®ï¼Œè€Œä¸æ˜¯ç›´æ¥è·³åˆ°åˆå§‹ä½ç½®
        joint_left = self.init_pos[0:6]
        joint_left[5] += 0.4101523743
        left_arm_init = np.concatenate([joint_left, np.array([0])])
        # print(left_arm_init.shape)

        joint_right = self.init_pos[12:18]
        # joint_right[5] += 0.4101523743
        right_arm_init = np.concatenate([joint_right, np.array([0])])

        for i in range(100):
            alpha = (i + 1) / 100.0
            interp_pos_left = (1 - alpha) * self.robot_left.get_joint_state() + alpha * left_arm_init
            self.robot_left.command_joint_state(interp_pos_left, "state")
            interp_pos_right = (1 - alpha) * self.robot_right.get_joint_state() + alpha * right_arm_init
            self.robot_right.command_joint_state(interp_pos_right, "state")
            time.sleep(0.03)
        # self.robot.command_joint_state(self.init_pos)

        self.hand_left.set_joint_positions(self.init_pos[6:12].astype(int).tolist())
        self.hand_right.set_joint_positions(self.init_pos[18:24].astype(int).tolist())

        self.take_action_cnt = 0
        self.eval_success = False
        time.sleep(0.5)
        cprint("âœ… å·²å°†piperé‡ç½®åˆ°åˆå§‹ä½ç½®", "green")

    def set_instruction(self, instruction: str, instruction_int: str = None, instruction_sim: str = None) -> None:
        """è®¾ç½®ä»»åŠ¡æŒ‡ä»¤ï¼ˆè¯­è¨€æè¿°ï¼‰"""
        self.instruction = instruction
        self.instruction_int = instruction_int
        self.instruction_sim = instruction_sim
        if instruction is not None:
            cprint(f"ğŸ“ ä»»åŠ¡æŒ‡ä»¤: {instruction}", "blue")
        if instruction_int is not None:
            cprint(f"ğŸ“ ä»»åŠ¡æŒ‡ä»¤_int: {instruction_int}", "blue")
        if instruction_sim is not None:
            cprint(f"ğŸ“ ä»»åŠ¡æŒ‡ä»¤_sim: {instruction_sim}", "blue")