import cv2
import os
import h5py
import numpy as np
from scipy.spatial.transform import Rotation as R

def adaptive_fixthre_endpose_sample_indices(
        start_idx: int,
        end_idx: int,
        traj: np.ndarray,
        rot_thresh: float = 10.0,       # deg
        trans_thresh: float = 0.015,    # m
        gripper_thresh: float = 0.5,
    ) -> np.ndarray:
    """
    æŒ‰æ—¶é—´æ­¥éå†ï¼šå¯¹äºæ¯ä¸ªæ—¶é—´ iï¼Œæ£€æŸ¥å·¦å³ä¸¤ä¾§ï¼ˆ0/1ï¼‰ç›¸å¯¹äºå®ƒä»¬å„è‡ªä¸Šæ¬¡è¢«é‡‡æ ·æ—¶åˆ»
    çš„ç´¯è®¡å˜åŒ–æ˜¯å¦è¶…è¿‡é˜ˆå€¼ã€‚å¦‚æœä»»ä¸€ä¾§è¶…è¿‡é˜ˆå€¼ï¼Œåˆ™é‡‡æ · iï¼ˆglobal idx = start_idx + iï¼‰ã€‚
    ä»…æ›´æ–°è§¦å‘é‡‡æ ·çš„ä¾§çš„ last_sampleã€‚

    traj: shape (T, 14)  æŒ‰é¡ºåºæ˜¯ [L_xyz, L_rpy, L_gripper, R_xyz, R_rpy, R_gripper]
    è¿”å›å…¨å±€ç´¢å¼• numpy array (sorted, unique)
    """
    assert 0 <= start_idx < end_idx <= traj.shape[0], f"invalid index, {start_idx}, {end_idx}"

    # å±€éƒ¨ç´¢å¼•èŒƒå›´ [0, N)
    N = end_idx - start_idx
    if N <= 0:
        return np.array([], dtype=np.int64)

    # ä»¥å±€éƒ¨ç´¢å¼•è®¿é—®åˆ‡ç‰‡
    traj_slice = traj[start_idx:end_idx]

    # åˆå§‹åŒ– last_sampleï¼ˆå±€éƒ¨ç´¢å¼•ï¼‰
    last_sample = [0, 0]  # left, right
    key_indices = [0]     # ä¿ç•™ç¬¬ä¸€å¸§ï¼ˆå±€éƒ¨ç´¢å¼•0ï¼‰

    # ä¾¿åˆ©çš„è®¿é—®å™¨ï¼šç»™ side è¿”å›å¯¹åº”åˆ‡ç‰‡åŒºé—´ offset
    def get_slice(i, side):
        off = 7 * side
        pos = traj_slice[i, off: off + 3]
        rpy = traj_slice[i, off + 3: off + 6]
        grip = float(traj_slice[i, off + 6])
        return pos, rpy, grip

    # ä¸»å¾ªç¯ï¼šæŒ‰æ—¶é—´æ­¥æ£€æŸ¥ä¸¤ä¾§
    for i in range(1, N):
        triggered = [False, False]

        for side in (0, 1):
            pos_i, rpy_i, grip_i = get_slice(i, side)
            pos_last, rpy_last, grip_last = get_slice(last_sample[side], side)

            # å¹³ç§»å·®
            d_trans = np.linalg.norm(pos_i - pos_last)

            # æ—‹è½¬å·®ï¼ˆscipy Rotation å•ä¸ªå¯¹å•ä¸ªï¼‰
            r1 = R.from_euler('xyz', rpy_last)
            r2 = R.from_euler('xyz', rpy_i)
            d_rot = np.degrees((r2 * r1.inv()).magnitude())

            # gripper å·®
            d_grip = abs(grip_i - grip_last)

            if (d_trans > trans_thresh) or (d_rot > rot_thresh) or (d_grip > gripper_thresh):
                triggered[side] = True

        # å¦‚æœä»»ä¸€ä¾§è§¦å‘ï¼Œé‡‡æ ·å½“å‰å¸§ i
        if triggered[0] or triggered[1]:
            key_indices.append(i)
            # ä»…æ›´æ–°è§¦å‘çš„ä¾§çš„ last_sampleï¼ˆæœªè§¦å‘çš„ä¾§ä¿ç•™åŸ last_sampleï¼‰
            for side in (0, 1):
                if triggered[side]:
                    last_sample[side] = i

    # ä¿è¯æœ«å¸§è¢«ä¿ç•™
    if key_indices[-1] != N - 1:
        key_indices.append(N - 1)

    # è½¬ä¸ºå…¨å±€ç´¢å¼•å¹¶å»é‡æ’åº
    key_indices = np.array(key_indices, dtype=np.int64)
    global_idx = start_idx + np.unique(key_indices)

    return global_idx

def read_endpose(file_path):
    """è¯»å– HDF5 æ–‡ä»¶ä¸­çš„ endpose æ•°æ®é›†"""
    with h5py.File(file_path, 'r') as hdf:
        if "endpose" not in hdf:
            raise KeyError(f"è¯¥æ–‡ä»¶ä¸­ä¸å­˜åœ¨ 'endpose' æ•°æ®é›†ï¼š{file_path}")
        data = hdf["endpose"][:]  # è¯»å–ä¸º numpy æ•°ç»„
    print(f"âœ… è¯»å–å®Œæˆ: endpose.shape = {data.shape}, dtype = {data.dtype}")
    return data


def explore_hdf5(file_path, preview_values=False, indent=0):
    """é€’å½’æ‰“å° HDF5 æ–‡ä»¶ä¸­æ‰€æœ‰ group å’Œ dataset çš„å±‚çº§ç»“æ„"""
    def print_attrs(name, obj):
        pad = "  " * indent
        if isinstance(obj, h5py.Group):
            print(f"{pad}ğŸ“‚ Group: {name}")
        elif isinstance(obj, h5py.Dataset):
            shape = obj.shape
            dtype = obj.dtype
            print(f"{pad}ğŸ“„ Dataset: {name} | shape={shape}, dtype={dtype}")
            if preview_values:
                data = obj[()]
                # ä»…å±•ç¤ºéƒ¨åˆ†æ•°æ®ï¼ˆé˜²æ­¢å¤ªå¤§ï¼‰
                preview = np.array2string(data.flatten()[:10], precision=4, separator=", ")
                print(f"{pad}   preview: {preview} ...")

    with h5py.File(file_path, 'r') as hdf:
        print(f"\nğŸ“˜ Exploring HDF5 file: {file_path}")
        hdf.visititems(print_attrs)

episode = 10
# è¾“å…¥è§†é¢‘è·¯å¾„

task = "beat_block_hammer_loop" 
# task = "cut_carrot_knife"
# task = "shake_bottle_loop"
# task = "double_knife_chop"
# task = "grab_roller_loop"
input_video = f"/home/liaohaoran/code/RoboTwin/data/{task}/loop1-8-all/video/episode{episode}.mp4"
data_path = f"/home/liaohaoran/code/RoboTwin/data/{task}/loop1-8-all/data/episode{episode}.hdf5"

data_key = "endpose"

data = read_endpose(data_path)

# data_dict = read_hdf5(data_path, data_key)

# data = np.concatenate(data, axis=1)



output = adaptive_fixthre_endpose_sample_indices(0, len(data), data)
print(output.shape)
print(output)

# è¾“å‡ºè§†é¢‘è·¯å¾„
output_video = f"/home/liaohaoran/code/RoboTwin/eval_result/test_sampling/{task}_video_{episode}.mp4"
ori_video = f"/home/liaohaoran/code/RoboTwin/eval_result/test_sampling/{task}_video_{episode}_ori.mp4"

# ç›®æ ‡å¸§åˆ—è¡¨ï¼ˆ0-basedç´¢å¼•ï¼Œè‹¥åŸåˆ—è¡¨æ˜¯1-basedéœ€å…ˆå‡1ï¼‰
target_frames = output
target_frames.sort()  # ç¡®ä¿å¸§æŒ‰é¡ºåºæ’åˆ—


# # æ‰“å¼€è§†é¢‘å¹¶è·å–åŸºæœ¬ä¿¡æ¯
# cap = cv2.VideoCapture(input_video)
# if not cap.isOpened():
#     print("æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶")
#     exit()

# frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))  # å¸§å®½åº¦
# frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  # å¸§é«˜åº¦
# fps = cap.get(cv2.CAP_PROP_FPS)  # å¸§ç‡
# total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # æ€»å¸§æ•°


# fourcc = cv2.VideoWriter_fourcc(*'mp4v')
# out = cv2.VideoWriter(ori_video, fourcc, fps, (frame_width, frame_height))

# # 4. å¾ªç¯è¯»å–å¹¶å†™å…¥å¸§
# while cap.isOpened():
#     ret, frame = cap.read()  # retï¼šæ˜¯å¦è¯»å–åˆ°å¸§ï¼›frameï¼šå¸§æ•°æ®
#     if not ret:
#         break  # æ— å¸§å¯è¯»æ—¶é€€å‡ºå¾ªç¯
#     out.write(frame)  # å†™å…¥å½“å‰å¸§åˆ°è¾“å‡ºè§†é¢‘

# # 5. é‡Šæ”¾èµ„æº
# cap.release()  # å…³é—­è¾“å…¥è§†é¢‘è¯»å–
# out.release()  # å…³é—­è¾“å‡ºè§†é¢‘å†™å…¥
# cv2.destroyAllWindows()  # å…³é—­å¯èƒ½æ‰“å¼€çš„çª—å£

# print(f"è§†é¢‘å·²ä¿å­˜è‡³ï¼š{ori_video}")




fps = 5  # æ–°è§†é¢‘çš„å¸§ç‡ï¼ˆå¯è‡ªå®šä¹‰ï¼Œå¦‚æ¯ç§’æ’­æ”¾2å¸§ï¼‰

# æ‰“å¼€è§†é¢‘å¹¶è·å–åŸºæœ¬ä¿¡æ¯
cap = cv2.VideoCapture(input_video)
if not cap.isOpened():
    print("æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶")
    exit()

frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))  # å¸§å®½åº¦
frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  # å¸§é«˜åº¦
fps = cap.get(cv2.CAP_PROP_FPS)  # å¸§ç‡
total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # æ€»å¸§æ•°

# è®¾ç½®ç¼–ç å™¨
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter(output_video, fourcc, fps, (frame_width, frame_height))

current_frame = 0
extracted_count = 0  # å·²æå–çš„å¸§æ•°

while cap.isOpened() and extracted_count < len(target_frames):
    ret, frame = cap.read()
    if not ret:
        break
    
    # æ£€æŸ¥å½“å‰å¸§æ˜¯å¦æ˜¯ç›®æ ‡å¸§
    if current_frame == target_frames[extracted_count]:
        out.write(frame)  # å†™å…¥æ–°è§†é¢‘
        extracted_count += 1  # ç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªç›®æ ‡å¸§
    
    current_frame += 1

# é‡Šæ”¾èµ„æº
cap.release()
out.release()


print(f"æŠ½å¸§åˆæˆè§†é¢‘å®Œæˆï¼š{output_video}")